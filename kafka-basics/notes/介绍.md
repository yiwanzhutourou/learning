# 介绍

Apache Kafka 是一个**分布式流处理平台**。一些概念：

- Kafka 作为一个集群，运行在一台或者多台服务器上。
- Kafka 通过主题（topic）对存储的流数据进行分类。
- 每条记录中包含一个 key，一个 value 和一个 timestamp。
- 客户端和服务器使用一个简单、高性能、支持多语言的 [TCP 协议](https://kafka.apache.org/protocol.html)。

## 主题和日志

主题（topic）是数据发布的地方，可以用来区分业务系统。Kafka 中的主题总是多定订阅者模式，一个主题可以拥有一个或者多个消费者来订阅它的数据。对于每一个主题，Kafka 集群都会维护一个分区日志，如下所示：

![Kafka topic](https://youdu-markdown.oss-cn-shanghai.aliyuncs.com/20191212193534.png)

每个分区都是有序且顺序不可变的记录集，并且不断地追加到结构化的日志文件中。分区中的每一个记录都会分配一个 id 来表示顺序，称为 offset，offset 唯一标识分区中的每条记录。

Kafka 集群保留所有发布的记录——无论它们是否已被消费——并通过一个可配置的保留期限参数来控制存储的时间。如果保留期限被设置为 2 天，那么一条记录在被发布后的 2 天内可以随时被消费。**Kafka 的性能和数据大小无关，所以长时间存储数据没有什么问题。**

在每一个消费者中唯一保存的元数据是偏移量（offset）。偏移量由消费者控制，通常情况下，消费者会以线性的方式增加偏移量，但实际上，消费者也可以重置到一个旧的的偏移量，重新处理过去的数据；也可以跳过最近的记录，从“现在”开始消费。

<img src="https://youdu-markdown.oss-cn-shanghai.aliyuncs.com/20191212194215.png" alt="消费偏移量" style="zoom:20%;" />

## 分布式

日志的分区（partition）分布在 Kafka 集群的服务器上。每个服务器在处理数据和请求时，共享这些分区。每一个分区都会在已配置的服务器上进行备份，确保容错性。每个分区都有一台服务器作为领导者（leader），零台或者多台服务器作为追随着（follwers） 。领导者服务器处理一切对分区的读写请求，而跟随者服务器只需被动的同步领导者服务器上的数据。当领导者服务器宕机了，追随者服务器中的一台服务器会自动成为新的领导者服务器。每台服务器都会成为某些分区的领导者服务器和某些分区的追随者服务器，因此集群的负载是平衡的。

## 生产者

生产者（Producer）可以将数据发布到所选择的主题中。生产者负责将记录分配到主题的哪一个分区中。可以使用循环的方式来简单地实现负载均衡，也可以根据某些语义分区函数来完成。

## 消费者和消费者组

消费者（Consumer）使用一个消费者组（Consumer Group）名称来标识，发布到主题中的每条记录都会被分配给订阅这个主题的消费者组中的一个消费者实例。消费者实例可以分布在多个进程中或者多个机器上。如果所有消费者实例在同一个消费者组中，消息记录会负载均衡到一个消费者实例（点对点）；如果所有的消费者实例在不同的消费者组中，每条消息记录会广播到所有的消费者进程（发布 / 订阅）。

![Kafka 集群示例](https://youdu-markdown.oss-cn-shanghai.aliyuncs.com/20191212201141.png)

如上图，这个 Kafka 集群有两台服务器，四个分区和两个消费者组，两个消费者组分别有 2 个和 4 个消费者。

在 Kafka 中实现消费的方式是**将日志中的分区划分到每一个消费者实例上**，以便在任何时间，每个实例都是分区唯一的消费者。维护消费者组中的消费关系由 Kafka 协议动态处理。如果新的实例加入组，他们将从组中其他成员处接管一些分区；如果一个实例消失，拥有的分区将被分发到剩余的实例。

Kafka 只保证分区内的记录是有序的，而不保证主题中不同分区的顺序。

## 保证

- 生产者发送到特定主题分区的消息将按照发送的顺序处理。 也就是说，如果记录 M1 和记录 M2 由相同的生产者发送，并先发送 M1 记录，那么 M1 的偏移比 M2 小，并在日志中较早出现。
- 一个消费者实例按照日志中的顺序查看记录。
- 对于具有 N 个副本的主题，我们最多容忍 N-1 个服务器故障，从而保证不会丢失任何提交到日志中的记录。

## Kafka 作为一个消息引擎系统（Messaging System）

- Kafka 通过引入消费者组增加了多消费者并行计算的能力。不管是点对点的消费模式还是发布 / 订阅消费模式，传统的消息引擎系统都会将消息发布到一个或者多个队列（queue），一个队列只能绑定一个消费者。

- Kafka 比传统消息引擎系统具有更严格的顺序保证。传统消息引擎系统在服务器上保存有序的记录，如果多个消费者消费队列中的数据，虽然然服务器按顺序输出记录，但是记录被异步传递给消费者，因此记录可能会无序地到达消费者。为了保证消息被顺序消费，传统消息引擎系统往往只能使用一个消费者实例消费消息，这就丧失了多消费者并行计算的能力。

通过在主题中引入分区的概念，并将分区绑定到消费者组内的特定消费者， Kafka 既可以保证消息被顺序消费（同一个消费者组内只有一个消费者消费某个特定分区），又可以将消息消费在多个消费者间做负载均衡。但是需要注意的是，消费者组内的消费者数量不能多于主题的分区数量。

## Kafka 作为一个存储系统

任何消息队列也都可以作为消息的存储系统。

Kafka 将数据保存到磁盘，并通过备份来容错。直到数据被完全备份，Kafka 才通知生产者写入完成，以此来保证数据的完整性。

Kafka 的存储结构具有很好的可扩展性。

Kafka 允许客户端控制数据的偏移量，因此你可以把 Kafka 看做一个高性能、低延迟、高可用、可伸缩的分布式文件系统。

## Kafka 用作流处理

Kafka 不仅仅用来读写和存储流式数据，它最终的目的是为了能够进行实时的流处理。在 Kafka 中，流处理器不断地从输入的主题获取流数据，处理数据后，再不断生产流数据到输出的主题中去。例如，零售应用程序可能会接收销售和出货的输入流，经过价格调整计算后，再输出一串流式数据。

简单的数据处理可以直接用生产者和消费者的 API。对于复杂的数据变换，Kafka 提供了 Streams API。 Stream API 允许应用做一些复杂的处理，比如将流数据聚合或者 join。