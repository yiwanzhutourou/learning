## 极客时间《如何设计一个秒杀系统》笔记

注：以下凡 *斜体* 的内容都是自己的思考，凡包括在引用内的内容都是原文摘抄，其他内容为内容总结。

注：凡是我觉得有价值的内容都会罗列出来，有些可能是提纲挈领的宏观思想，有些又会涉及到具体的技术、工具，主要是原专栏有的时候太不“细节”，有的时候又会提到具体的技术、工具。涉及到的具体的技术、工具其实也只是一笔带过，有价值的需要再仔细研究。

*《如何设计一个秒杀系统》的内容主要是阿里的前技术专家针对“秒杀”这个场景，讲解如何设计一个高并发、高可用的系统。我觉得整个专栏的主要价值在于提供了一些设计的原则和思路，至于具体如何落地，还需要根据生产中，业务的体量和实际情况再做实践。专栏的另外一个价值也在于透露了一些阿里这样的大厂关于如何做高并发、高可用系统的思路。*

#### 开篇

> 简单来说，秒杀就是在同一个时刻有大量的请求争抢购买同一个商品并完成交易的过程，用技术的行话来说就是大量的并发读和并发写。

> **秒杀其实主要解决两个问题，一个是并发读，一个是并发写。**并发读的核心优化理念是尽量减少用户到服务端来“读”数据，或者让他们读更少的数据；并发写的处理原则也一样，它要求我们在数据库层面独立出来一个库，做特殊的处理。另外，我们还要针对秒杀系统做一些保护，针对意料之外的情况设计兜底方案，以防止最坏的情况发生。

*这里提到了几个核心思路。一是利用缓存减少服务器压力，静态数据走 CDN 缓存减少用户直接请求服务器的数量，动态数据走 redis 缓存减少数据库读压力。二是数据库分库，热点数据分散到不同的库里可以避免大量并发写请求落到一个数据库上。三是一定要设计兜底方案，避免最坏的情况——例如，服务器直接宕机——的发生。*

从架构角度，我们的系统应该满足以下几个方面的要求：

- 高性能。可以支持大量的并发读写。可以从**动静分离、热点数据的发现和隔离、削峰填谷、服务端性能优化**等方面考虑。
- 一致性。在大量并发写的情况下仍要保证数据的一致性，例如秒杀扣库存不能多扣。
- 高可用。一定要设计 Plan B 兜底方案，即使出现最坏的情况，也有应对方案。

#### 5 个架构原则（4 要 1 不要）

1. 数据要尽量少

   其一，减少请求服务器的数据和服务器返回的数据，可以减少服务器对数据压缩、编解码的时间，而这些操作都非常消耗 CPU。

   其二，减少系统依赖的数据，包括系统完成某些业务逻辑需要读取和保存的数据。这些数据要么来自于依赖的后台服务，要么来自于数据库。调用其他服务涉及数据的序列化反序列化，而数据库往往容易成为瓶颈。

   *这里我的理解是，专栏讲解的是“秒杀”这样的场景下的极致优化，这里提到的“减数据”除了从代码层面做到尽量精简外，还需要从业务角度来做精简。因此，在设计系统时可以考虑与业务沟通，做到性能和易用性的平衡。如果是“秒杀”这样的场景，或者是可以预计到的大流量场景，可以考虑只提供核心功能，例如秒杀页面上尽量减少相关产品的展示。*

2. 请求数量尽量少

   页面依赖的 CSS / Javascript、图片以及 Ajax 等额外请求应该尽量少。例如，减少请求数最常用的一个实践就是合并 CSS 和 JavaScript 文件，把多个 JavaScript 文件合并成一个文件，在 URL 中用逗号隔开。文件在服务端仍单独存放，只是服务端会有一个组件解析这个 URL，然后动态把这些文件合并起来一起返回。

3. 路劲要尽量短

   缩短请求路径不仅可以增加可用性，同样可以有效提升性能（减少中间节点可以减少数据的序列化与反序列化），并减少延时（可以减少网络传输耗时）。要缩短访问路径有一种办法，就是多个相互强依赖的应用合并部署在一起，把远程过程调用（RPC）变成 JVM 内部之间的方法调用。（《大型网站技术架构演进与性能优化》里有一章介绍了这种技术的详细实现。）

4. 依赖要尽量少

    > 要减少依赖，我们可以给系统进行分级，比如 0 级系统、1 级系统、2 级系统、3 级系统，0 级系统如果是最重要的系统，那么 0 级系统强依赖的系统也同样是最重要的系统，以此类推。
    >
    > 注意，0 级系统要尽量减少对 1 级系统的强依赖，防止重要的系统被不重要的系统拖垮。例如支付系统是 0 级系统，而优惠券是 1 级系统的话，在极端情况下可以把优惠券给降级，防止支付系统被优惠券这个 1 级系统给拖垮。

5. 不要有单点

    > 系统中的单点可以说是系统架构上的一个大忌，因为单点意味着没有备份，风险不可控，我们设计分布式系统最重要的原则就是“消除单点”。
    >
    > **架构是一种平衡的艺术，而最好的架构一旦脱离了它所适应的场景，一切都将是空谈。我希望你记住的是，这里所说的几点都只是一个个方向，你应该尽量往这些方向上去努力，但也要考虑平衡其他因素。**

    *我的理解是，任何架构上的设计都应该根据实际情况来，是对性能和通用性的平衡。优化往往不是发生在系统的第一个版本，而是发生在出现实际需要的时候。例如，我们可能先设计出一个通用的交易平台，能够满足目前的以及可预见的业务体量即可，等到公司需要出现一个“秒杀”的业务场景时，再做针对性优化。又例如，专栏中有提到秒杀商品数据库可以是一个独立于普通商品的数据库，避免少量热点数据影响其他正常数据的读写。我们在最初设计商品中心的时候往往是先把精力放在如何设计一个通用的、易于扩展的商品服务，而不会在一开始就考虑这样一个库的存在。当然，如何在系统设计之初就遇见到这些情况，留有扩展的余地，也是需要考量的。*

#### 动静分离

“静态数据”不单单指前后端分离后的 HTML、CSS、JavaScript 等静态文件，也包括 Java 动态生成的，但是与“浏览者、时间、地域等”无关的数据，例如媒体网站的文章就是静态数据，推荐商品就是动态数据。

*我理解其实静态数据大部分就是指静态的 HTML、CSS、JavaScript 文件了，前后端分离已经是目前的大方向了，这些静态文件可以做 CDN 缓存从而减少用户直接访问服务器的数量。至于 Java 动态生成的所谓“静态数据”我们往往也很容易区分，这些数据往往也不能做 CDN 缓存，而是利用 redis 或者甚至服务器本地内存等缓存来减少对数据库的压力。*

#### 热点数据问题

1. 如何发现热点数据？可以**考虑**以下几种“思路”：

- 从业务角度发现。例如，参加秒杀活动必须先报名，利用这种方式提前发现热点数据，再利用后台运营工具，在活动开始前将这些数据提前写进缓存。
- 从大数据角度提前发现。例如，对平台每天的被访问、加入购物车、购买的商品做统计，计算出 TOP N 的商品，可以认为这些 TOP N 的商品就是热点数据。
- **动态发现热点数据。**利用请求从上游系统到下游系统之间的时间差，在整个系统链路上构建一个异步的收集、上报热点数据的机制。例如在 Nginx、缓存、上游系统中发现热点数据的 Key 值，利用消息队列等发布热点数据的广播，下游系统可以订阅这些消息，提前识别出热点数据，将其加入缓存。主要目的是通过交易链路上各个系统（包括详情、购物车、交易、优惠、库存、物流等）访问的时间差，把上游已经发现的热点透传给下游系统，提前做好保护。

    > 热点发现要做到接近实时（3s 内完成热点数据的发现），因为只有做到接近实时，动态发现才有意义，才能实时地对下游系统提供保护。

2. 如何处理热点数据？可以**考虑**以下几种“思路”：

- 缓存。根据需要，缓存到 redis 集群，或者本地内存。需要考虑好缓存失效的策略、缓存的数据量大小、如何应对缓存穿透等问题。
- 限制。例如对被访问商品的 ID 做一致性 Hash，然后根据 Hash 分桶，每个分桶设置一个处理队列，这样可以把热点商品限制在一个请求队列里，防止因某些热点商品占用太多的服务器资源，而使其他请求始终得不到服务器的处理资源。
- 隔离。例如，启用单独的数据库、单独的 Cache 集群存放热点数据。

#### 流量削峰

1. 利用消息队列来缓冲瞬时流量，保证下游系统始终可以匀速处理请求，不至于被上游系统瞬间的大流量拖垮。

    *如果“秒杀”系统直接采用这种方法，在收到用户请求后立即返回，将请求直接加入消息队列慢慢处理，似乎可以增加整个服务器的吞吐量，但是因为必须“异步”告知用户结果，似乎在业务上并不能被接受。另外，在“秒杀”这样的场景下，只有小部分用户最终可以抢到商品，因此把很多无效请求加入到队列也是没必要的。*

2. 利用业务手段削峰。例如答题，利用答题其一可以防止秒杀器作弊，其二可以延缓请求，将 1s 内的流量高峰分散到 2s - 10s。

#### 服务端性能优化

1. 服务端性能指标：

- QPS（Queries Per Second），每秒可以处理的请求数。
- 响应时间（Response Time），服务器处理每一个请求的时间，由 CPU 执行时间和等待时间（I/O、锁）两部分组成。

2. 减少等待时间对 QPS 的提升不是线性的，因为我们可以通过调整线程的数量来提升 QPS。例如，对于等待时间长的任务，增加线程数可以增加 CPU 利用率，继而提高 QPS。
3. 提升 CPU 时间对 QPS 的提升是线性的，因为 CPU 的执行真正消耗了服务器的资源，减少 CPU 一半的执行时间，就可以增加一倍的 QPS。
4. 两个公式：

- 总 QPS =（1 s / 响应时间）× 线程数量

- 线程数 = [(线程等待时间 + 线程 CPU 时间) / 线程 CPU 时间] × CPU 数量

  其中第二个其实是一个经验公式，思想就是利用增加线程数达到充分利用 CPU 的目的，当然线程不是越多越好，线程数多到超出了 CPU 的处理能力，反而增加了线程切换带来的损耗。最好的办法当然是通过压测找出线程的合理数量。

*这里线程模型其实我一直理解不到位，对于线程数应该如何选取的认识也很模糊。当然，在开发系统时肯定要做优化，优化的考量主要是，要么减少 CPU 执行时间，即优化本机代码性能；要么减少 I/O 时间，即尽量减少外部系统的响应时间，优化 SQL 性能等；要么优化系统中各种锁的粒度，减少等待时间。以上优化手段都是基础，当然可以降低请求的响应时间，提升 QPS。但是，在这个基础上，还应该通过经验和实际的压测再设置一个合理的线程数，这一点我之前往往忽略了。以上的理论是站在宏观角度理解这个问题，一个系统本身有很多接口，不同接口的访问量也是不同的，系统内可能还有各种其他线程池存在，如何设置线程池大小可以先猜测，然后根据压测情况再调整。*

*关于降低等待时间和 CPU 时间对系统性能的影响，可以用下面理想化的数据直观理解。假设系统等待时间只有 I/O 时间，第一行数据是一个基准，后两行数据分别在第一行数据的基础上降低一半的 I/O 时间和一半的 CPU 时间。*

| CPU 时间 | I/O 时间 | CPU 核心数 | 合理线程数 | QPS  |
| -------- | -------- | ---------- | ---------- | ---- |
| 0.5      | 1        | 1          | 3          | 2    |
| 0.5      | 0.5      | 1          | 2          | 2    |
| 0.25     | 1        | 1          | 5          | 4    |
5. 如何发现 CPU 瓶颈？

- 利用 **JProfiler** 和 **Yourkit**，列出每一个函数的 CPU 执行时间做针对性优化。
- 通过 **jstack** 定时打印调用栈，耗时多的函数会频繁出现在调用栈里。
- 一个简单的判断 CPU 是否成为瓶颈的方法就是看当 QPS 达到极限时，服务器的 CPU 使用率是否在 95% 以上。

6. 如何优化？对于 Java 系统，以下是几个比较有效的手段，供参考。

- 减少编码

    > 那么如何才能减少编码呢？例如，网页输出是可以直接进行流输出的，即用 resp.getOutputStream() 函数写数据，把一些静态的数据提前转化成字节，等到真正往外写的时候再直接用 OutputStream() 函数写，就可以减少静态数据的编码转换。
    >
    > 我在《深入分析 Java Web 技术内幕》一书中介绍的“Velocity 优化实践”一章的内容，就是基于把静态的字符串提前编码成字节并缓存，然后直接输出字节内容到页面，从而大大减少编码的性能消耗的，网页输出的性能比没有提前进行字符到字节转换时提升了 30% 左右。

    *编码（包括下面的序列化）相关的问题平时确实没有考虑过。网络 I/O 涉及到将字符转换为字节，这个转换必须编码，而 Java 的编码速度非常慢。编码是比较耗 CPU 资源的，因此要意识到，看起来是 I/O 操作，其中的编解码也是占用 CPU 资源的！*

    *当然这部分优化似乎是要牺牲框架的通用性的，在实际生产中如果要做这样的字符编码优化可以再看。*

- 减少序列化

    > 序列化大部分是在 RPC 中发生的，因此避免或者减少 RPC 就可以减少序列化，当然当前的序列化协议也已经做了很多优化来提升性能。有一种新的方案，就是可以将多个关联性比较强的应用进行“合并部署”，而减少不同应用之间的 RPC 也可以减少序列化的消耗。
    >
    > 所谓“合并部署”，就是把两个原本在不同机器上的不同应用合并部署到一台机器上，当然不仅仅是部署在一台机器上，还要在同一个 Tomcat 容器中，且不能走本机的 Socket，这样才能避免序列化的产生。

- Java 极致优化
  - 直接用 Servlet 处理请求，而不使用传统的 MVC 框架，这样可以绕过一堆复杂逻辑，节约 1ms 时间。
  - 直接输出数据流，直接使用 resp.getOutputStream() 输出字节流，省掉编解码的时间。
- 并发读优化

  - 使用机器本地内存加分布式两级缓存。这样一些热点数据可以缓存到本机，进一步提升并发读性能。甚至，库存这样的动态数据也可以短暂缓存到本机内存，允许读场景下有一定的脏数据，而只是在写的时候最终保证数据一致。

> 此外，要做好优化，你还需要做好应用基线，比如性能基线（何时性能突然下降）、成本基线（去年双 11 用了多少台机器）、链路基线（我们的系统发生了哪些变化），你可以通过这些基线持续关注系统的性能，做到在代码上提升编码质量，在业务上改掉不合理的调用，在架构和调用链路上不断的改进。

*感觉这里提到的很多内容都是做好基础之后的“额外”工作，我们平时在基于框架的基础上做好系统开发，做好基础优化，如果还需要针对极端情况做特殊优化，就要牺牲一些框架通用性了。*

#### 库存怎么减？

1. 下单减库存

    简单，容易做到数据一致。但是要应对恶意锁库存的情况。

2. 付款减库存

    实现略复杂，为了保证不超卖，可能出现用户无法付款的情况。

3. 预扣库存

    下单后库存为其保留 10 分钟，付款时检查库存是否还在。

    *其实这里感觉有些复杂了，现在的电商不都是下单后如果半小时内不付款就自动关闭交易继而退还库存吗？用户也是理解这种情况下需要去重新下单的。至于秒杀场景下我们完全可以把这个超时时间设短一些，例如 10 分钟，秒杀情况下抢到又不付款的毕竟还在少数。*

#### 减库存的优化

1. 是否可以考虑将减库存的操作放到 redis 层？

    > 如果你的秒杀商品的减库存逻辑非常单一，比如没有复杂的 SKU 库存和总库存这种联动关系的话，我觉得完全可以。但是如果有比较复杂的减库存逻辑，或者需要使用事务，你还是必须在数据库中完成减库存。

    *这里是不是可以考虑用 redis 层做库存校验，如果可以扣减成功就认为秒杀成功了，订单系统就可以正常走流程给用户下单了，至于商品的库存系统可以异步更新数据库，保证数据的最终一致性即可。*

2. 如果用 MySQL 数据库来做减库存，对于某些热点商品可能会出现大量修改同一行的情况，继而降低整个数据库的吞吐量。可以考虑将热点数据隔离到其他数据库中，这样不会影响到非秒杀商品的正常下单购买。当然，要解决数据库并发锁问题，可以考虑在应用层 / 数据库层做排队（**InnoDB 内部的死锁检测，以及 MySQL Server 和 InnoDB 的切换会比较消耗性能**）。

#### Plan B 兜底方案

1. 高可用建设应该发生在系统的整个生命周期。

   > 网站的高可用建设是基础，可以说要深入到各个环节，更要长期规划并进行体系化建设，要在预防（建立常态的压力体系，例如上线前的单机压测到上线后的全链路压测）、管控（做好线上运行时的降级、限流和兜底保护）、监控（建立性能基线来记录性能的变化趋势以及线上机器的负载报警体系，发现问题及时预警）和恢复体系（遇到故障要及时止损，并提供快速的数据订正工具等）等这些地方加强建设，每一个环节可能都有很多事情要做。

- **架构阶段**要考虑系统的可扩展性（*可弹性伸缩*）和容错性（*设计降级方案*），避免出现单点。
- **编码阶段**保证代码的健壮性。例如，远程调用要设置超时时间，要对返回的结果集有预期，做好在错误情况下的默认处理。
- **测试阶段**保证测试的覆盖度，预演最坏情况发生的应对。
- **发布阶段**要有应急回滚机制。
- **运行阶段**做好监控和报警。
- **故障发生**时及时止损，例如由于程序问题导致商品价格错误，那就要及时下架商品或者关闭购买链接，防止造成重大资产损失。然后就是要能够及时恢复服务，并定位原因解决问题。

2. 降级

   可以在系统内设置各种开关，遇到大流量时方便切换，例如某个开关打开后，某些接口返回结果的数据集从 20 降低到 5，甚至某些接口可以直接返回事先准备好的默认数据。

   > 执行降级无疑是在系统性能和用户体验之间选择了前者，降级后肯定会影响一部分用户的体验，例如在双 11 零点时，如果优惠券系统扛不住，可能会临时降级商品详情的优惠信息展示，把有限的系统资源用在保障交易系统正确展示优惠信息上，即保障用户真正下单时的价格是正确的。所以降级的核心目标是牺牲次要的功能和用户体验来保证核心业务流程的稳定，是一个不得已而为之的举措。

3. 限流

   可以考虑客户端限流和服务端限流。

   > 在限流的实现手段上来讲，基于 QPS 和线程数的限流应用最多，最大 QPS 很容易通过压测提前获取，例如我们的系统最高支持 1w QPS 时，可以设置 8000 来进行限流保护。线程数限流在客户端比较有效，例如在远程调用时我们设置连接池的线程数，超出这个并发线程请求，就将线程进行排队或者直接超时丢弃。
   >
   > 限流无疑会影响用户的正常请求，所以必然会导致一部分用户请求失败，因此在系统处理这种异常时一定要设置超时时间，防止因被限流的请求不能 fast fail（快速失败）而拖垮系统。

4. 拒绝服务

   当系统负载达到一定程度时直接拒绝服务，例如在最前端的 Nginx 上设置过载保护，当机器负载达到某个值时直接拒绝 HTTP 请求并返回 503 错误码，在 Java 层同样也可以设计过载保护。

   > 拒绝服务可以说是一种不得已的兜底方案，用以防止最坏情况发生，防止因把服务器压跨而长时间彻底无法提供服务。像这种系统过载保护虽然在过载时无法提供服务，但是系统仍然可以运作，当负载下降时又很容易恢复，所以每个系统和每个环节都应该设置这个兜底方案，对系统做最坏情况下的保护。

